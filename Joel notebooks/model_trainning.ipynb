{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8316b927-a051-41b0-9e09-8a0070e399c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Libraries that are used for training the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Clean and transformd data\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d411985c-0ea9-4bf1-88c3-fe9e6057980f",
   "metadata": {},
   "source": [
    "See the whole size of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84aca8e1-b16d-4ae1-9963-b852a7938bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49320"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real1 = pd.read_csv('../data/real1/snv-parse-real1-labeled.txt', sep='\\t', dtype={'Chr': str})\n",
    "real1['Chr'] = real1['Chr'].astype('str') \n",
    "len(real1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fade9a4b-66df-413c-8eb7-c356f9bd1f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22600"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real2 = pd.read_csv('../data/real2_part1/snv-parse-real2_part1-labeled.txt', sep='\\t', dtype={'Chr': str})\n",
    "real2['Chr'] = real2['Chr'].astype('str') \n",
    "len(real2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7824a678-2b39-4353-bb50-9776ccd776be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47880"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn1 = pd.read_csv('../data/syn1/snv-parse-syn1-labeled.txt', sep='\\t', dtype={'Chr': str})\n",
    "syn1['Chr'] = syn1['Chr'].astype('str') \n",
    "len(syn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d56a630-957a-4838-9d29-e62244fe8f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45376"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn2 = pd.read_csv('../data/syn2/snv-parse-syn2-labeled.txt', sep='\\t', dtype={'Chr': str})\n",
    "syn2['Chr'] = syn2['Chr'].astype('str') \n",
    "len(syn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42068c56-bd6b-4ca7-a551-51d845ae5493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44926"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn3 = pd.read_csv('../data/syn3/snv-parse-syn3-labeled.txt', sep='\\t', dtype={'Chr': str})\n",
    "syn3['Chr'] = syn3['Chr'].astype('str') \n",
    "len(syn3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78118536-e5a7-416a-b3e9-961da6312e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49884"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn4 = pd.read_csv('../data/syn4/snv-parse-syn4-labeled.txt', sep='\\t', dtype={'Chr': str})\n",
    "syn4['Chr'] = syn4['Chr'].astype('str') \n",
    "len(syn4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a8091fc-ca02-4a24-8015-83c8ef2d9185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46235"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn5 = pd.read_csv('../data/syn5/snv-parse-syn5-labeled.txt', sep='\\t', dtype={'Chr': str})\n",
    "syn5['Chr'] = syn5['Chr'].astype('str') \n",
    "len(syn5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbfa9ec-8b27-4939-be25-5ae99a6bd120",
   "metadata": {},
   "source": [
    "Print the size of the total dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "094e6fc5-85b5-4a3a-bd38-cecbb92e4c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306221"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(real1))+(len(real2))+(len(syn1))+(len(syn2))+(len(syn3))+(len(syn4))+(len(syn5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac9af4-24c2-473d-88b2-937210cfb2a2",
   "metadata": {},
   "source": [
    "See the 70% that will be used for the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e90f896-c675-4df0-b544-b376a4b69da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214354.69999999998"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((len(real1))+(len(real2))+(len(syn1))+(len(syn2))+(len(syn3))+(len(syn4))+(len(syn5))) * .7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b78c8f-77be-4f20-88cb-619fef523b30",
   "metadata": {},
   "source": [
    "The datasets below will be the ones to be used for training the model. To prevent overfitting and having the best accurate model, we will only be performing the training on the next four datasets. With this we will have our own training, validation, and testing datasets. After obtaining the model, we will compare the results with the other datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02aef21c-0be7-46a9-8469-2fd499b15923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238695"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(real1))+(len(syn1))+(len(syn2))+(len(syn4))+(len(syn5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b29b71c0-7eaf-42bc-a484-596989535d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188811"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat([real1, syn1, syn2, syn5], ignore_index=True)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72570c4f-0837-432d-83c5-6dca055f913f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chr</th>\n",
       "      <th>START_POS_REF</th>\n",
       "      <th>END_POS_REF</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "      <th>REF_MFVdVs</th>\n",
       "      <th>ALT_MFVdVs</th>\n",
       "      <th>Sample_Name</th>\n",
       "      <th>FILTER_Mutect2</th>\n",
       "      <th>FILTER_Freebayes</th>\n",
       "      <th>FILTER_Vardict</th>\n",
       "      <th>FILTER_Varscan</th>\n",
       "      <th>m2_MQ</th>\n",
       "      <th>f_MQMR</th>\n",
       "      <th>vs_SSC</th>\n",
       "      <th>vs_SPV</th>\n",
       "      <th>vd_SSF</th>\n",
       "      <th>vd_MSI</th>\n",
       "      <th>True_SNV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13110</td>\n",
       "      <td>13110</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G/NA/G/G/</td>\n",
       "      <td>A/NA/A/A/</td>\n",
       "      <td>icgc_cll-T</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>41.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.522430</td>\n",
       "      <td>0.23427</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15015</td>\n",
       "      <td>15015</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>G/NA/NA/G/</td>\n",
       "      <td>C/NA/NA/C/</td>\n",
       "      <td>icgc_cll-T</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>43.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.302390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16949</td>\n",
       "      <td>16949</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NA/NA/NA/A/</td>\n",
       "      <td>NA/NA/NA/C/</td>\n",
       "      <td>icgc_cll-T</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.023282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>40552</td>\n",
       "      <td>40552</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>NA/NA/NA/T/</td>\n",
       "      <td>NA/NA/NA/C/</td>\n",
       "      <td>icgc_cll-T</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>46907</td>\n",
       "      <td>46907</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>NA/NA/NA/T/</td>\n",
       "      <td>NA/NA/NA/C/</td>\n",
       "      <td>icgc_cll-T</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.017670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Chr  START_POS_REF  END_POS_REF REF ALT   REF_MFVdVs   ALT_MFVdVs  \\\n",
       "0   1          13110        13110   G   A    G/NA/G/G/    A/NA/A/A/   \n",
       "1   1          15015        15015   G   C   G/NA/NA/G/   C/NA/NA/C/   \n",
       "2   1          16949        16949   A   C  NA/NA/NA/A/  NA/NA/NA/C/   \n",
       "3   1          40552        40552   T   C  NA/NA/NA/T/  NA/NA/NA/C/   \n",
       "4   1          46907        46907   T   C  NA/NA/NA/T/  NA/NA/NA/C/   \n",
       "\n",
       "  Sample_Name  FILTER_Mutect2  FILTER_Freebayes  FILTER_Vardict  \\\n",
       "0  icgc_cll-T            True             False           False   \n",
       "1  icgc_cll-T            True             False           False   \n",
       "2  icgc_cll-T           False             False           False   \n",
       "3  icgc_cll-T           False             False           False   \n",
       "4  icgc_cll-T           False             False           False   \n",
       "\n",
       "   FILTER_Varscan  m2_MQ  f_MQMR  vs_SSC    vs_SPV   vd_SSF  vd_MSI  True_SNV  \n",
       "0           False  41.91     NaN     2.0  0.522430  0.23427     2.0     False  \n",
       "1           False  43.42     NaN     5.0  0.302390      NaN     NaN     False  \n",
       "2            True    NaN     NaN    16.0  0.023282      NaN     NaN     False  \n",
       "3            True    NaN     NaN    26.0  0.002231      NaN     NaN     False  \n",
       "4            True    NaN     NaN    17.0  0.017670      NaN     NaN     False  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231fa6cf-6f4d-4bca-b3e2-3bc34de8021e",
   "metadata": {},
   "source": [
    "Count all the rows that have a null value. As we can see, m2_mQ have similar amount of missing values. Then cv_SSC and vs_SPV similar amount of null values, and vd_SSF with vs_MSI have the same amount of null values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7349e38-7cee-4630-bd81-7c063c3611c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chr                      0\n",
       "START_POS_REF            0\n",
       "END_POS_REF              0\n",
       "REF                      0\n",
       "ALT                      0\n",
       "REF_MFVdVs               0\n",
       "ALT_MFVdVs               0\n",
       "Sample_Name              0\n",
       "FILTER_Mutect2           0\n",
       "FILTER_Freebayes         0\n",
       "FILTER_Vardict           0\n",
       "FILTER_Varscan           0\n",
       "m2_MQ               107339\n",
       "f_MQMR              116574\n",
       "vs_SSC               36951\n",
       "vs_SPV               36951\n",
       "vd_SSF               90405\n",
       "vd_MSI               90405\n",
       "True_SNV                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aac5f7-3d16-41af-9890-18ebc3d64dfa",
   "metadata": {},
   "source": [
    "# Train the model with only the SNV callers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf93dfa-93a0-485f-a803-759fcfa6fd89",
   "metadata": {},
   "source": [
    "The next step is we are going to just take the columsn of fiter mutec2, frebayes, vardict, and varscan to train the model. Also, we will include the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcc0a055-1015-480e-941d-cac87d6cf2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILTER_Mutect2</th>\n",
       "      <th>FILTER_Freebayes</th>\n",
       "      <th>FILTER_Vardict</th>\n",
       "      <th>FILTER_Varscan</th>\n",
       "      <th>True_SNV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FILTER_Mutect2  FILTER_Freebayes  FILTER_Vardict  FILTER_Varscan  True_SNV\n",
       "0            True             False           False           False     False\n",
       "1            True             False           False           False     False\n",
       "2           False             False           False            True     False\n",
       "3           False             False           False            True     False\n",
       "4           False             False           False            True     False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_read = [\"FILTER_Mutect2\", \"FILTER_Freebayes\", \"FILTER_Vardict\", \"FILTER_Varscan\", \"True_SNV\"]\n",
    "only_SNV_callers = dataset[columns_to_read]\n",
    "only_SNV_callers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74275d81-bdc4-47d7-ac14-44ea6ebefa8c",
   "metadata": {},
   "source": [
    "Separate the dataset only in features and results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "964add30-2ca7-48a9-b3ed-0c86f2b24341",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = only_SNV_callers.iloc[:, :-1].values\n",
    "y = only_SNV_callers.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6719255-c73a-444d-a3bf-9402b09ecad3",
   "metadata": {},
   "source": [
    "Separate the dataset into training set and testing set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e90ded-e4ce-41c6-9800-b4998d9a165b",
   "metadata": {},
   "source": [
    "### Train Linear SVC\n",
    "Train the model Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b92a28e-3bf9-49a7-a5e2-bca641c33710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9635791068177892"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.7, random_state = 0, stratify=y)\n",
    "classifier_linearSVC = LinearSVC(random_state=0, dual=False)  # `dual=False` improves performance for large datasets\n",
    "classifier_linearSVC.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier_linearSVC.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a760a40-d2d0-4b56-91f9-b7a4992fa993",
   "metadata": {},
   "source": [
    "### Train traditional SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3c711bd9-2096-4710-bbbb-4b0430cd2025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.962877030162413"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use only 10% of the dataset to train because if not then the SVM will take too long\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.90, random_state = 0, stratify=y)\n",
    "\n",
    "classifier_SVC = SVC(kernel='linear', random_state=0) # classic model with the linear kernel\n",
    "classifier_SVC.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier_SVC.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7f441c-c206-40cc-98d9-efed82a1a89d",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "575453b6-f919-4c9e-952e-486c9c1db752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9635791068177892"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.7, random_state = 0, stratify=y)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "# Approximate the RBF kernel\n",
    "rbf_feature = RBFSampler(gamma=1, random_state=0)\n",
    "X_train_rbf = rbf_feature.fit_transform(X_train)\n",
    "X_test_rbf = rbf_feature.transform(X_test)\n",
    "\n",
    "# Train with SGDClassifier (approximate SVM with RBF)\n",
    "sgd_rbf = SGDClassifier(loss='hinge', random_state=0)\n",
    "sgd_rbf.fit(X_train_rbf, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = sgd_rbf.predict(X_test_rbf)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110ee073-4c70-4590-847f-7cda559ab3fd",
   "metadata": {},
   "source": [
    "### Kernel Approximation + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cdda5323-6b51-4251-b686-05597e31138e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9635791068177892"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.7, random_state = 0, stratify=y)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "# RBF kernel approximation\n",
    "rbf_feature = RBFSampler(gamma=1, random_state=0)\n",
    "X_train_rbf = rbf_feature.fit_transform(X_train)\n",
    "X_test_rbf = rbf_feature.transform(X_test)\n",
    "\n",
    "# Train logistic regression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_rbf, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = log_reg.predict(X_test_rbf)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da0618-4bf4-4fcc-8f4e-5f547c649485",
   "metadata": {},
   "source": [
    "### Random Fourier Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d80b4f20-b57a-41b7-851d-d51c4d620199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9635791068177892"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.7, random_state = 0, stratify=y)\n",
    "\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Approximate RBF kernel using Fourier Features\n",
    "rbf_feature = RBFSampler(gamma=1, random_state=0)\n",
    "X_train_rbf = rbf_feature.fit_transform(X_train)\n",
    "X_test_rbf = rbf_feature.transform(X_test)\n",
    "\n",
    "# Train LinearSVC on transformed features\n",
    "classifier_rbf_approx = LinearSVC(random_state=0)\n",
    "classifier_rbf_approx.fit(X_train_rbf, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = log_reg.predict(X_test_rbf)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e459a07-7d2b-426e-bc50-e85676525e3b",
   "metadata": {},
   "source": [
    "# Train the model with SNV callers + 6 other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "07ae706a-c60b-4cb1-bb5b-f45518a38277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILTER_Mutect2</th>\n",
       "      <th>FILTER_Freebayes</th>\n",
       "      <th>FILTER_Vardict</th>\n",
       "      <th>FILTER_Varscan</th>\n",
       "      <th>m2_MQ</th>\n",
       "      <th>f_MQMR</th>\n",
       "      <th>vs_SSC</th>\n",
       "      <th>vs_SPV</th>\n",
       "      <th>vd_SSF</th>\n",
       "      <th>vd_MSI</th>\n",
       "      <th>True_SNV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>41.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.522430</td>\n",
       "      <td>0.23427</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>43.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.302390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.023282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.017670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FILTER_Mutect2  FILTER_Freebayes  FILTER_Vardict  FILTER_Varscan  m2_MQ  \\\n",
       "0            True             False           False           False  41.91   \n",
       "1            True             False           False           False  43.42   \n",
       "2           False             False           False            True    NaN   \n",
       "3           False             False           False            True    NaN   \n",
       "4           False             False           False            True    NaN   \n",
       "\n",
       "   f_MQMR  vs_SSC    vs_SPV   vd_SSF  vd_MSI  True_SNV  \n",
       "0     NaN     2.0  0.522430  0.23427     2.0     False  \n",
       "1     NaN     5.0  0.302390      NaN     NaN     False  \n",
       "2     NaN    16.0  0.023282      NaN     NaN     False  \n",
       "3     NaN    26.0  0.002231      NaN     NaN     False  \n",
       "4     NaN    17.0  0.017670      NaN     NaN     False  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat([real1, syn1, syn2, syn5], ignore_index=True)\n",
    "columns_to_read = [\"FILTER_Mutect2\", \"FILTER_Freebayes\", \"FILTER_Vardict\", \"FILTER_Varscan\", \"m2_MQ\", \"f_MQMR\", \"vs_SSC\", \"vs_SPV\", \"vd_SSF\", \"vd_MSI\", \"True_SNV\"]\n",
    "only_SNV_callers = dataset[columns_to_read]\n",
    "only_SNV_callers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adea1eb-77d0-4ac2-ae8c-571f6035d4eb",
   "metadata": {},
   "source": [
    "The code belows does this: \n",
    "1. For each continous column, get the 25%, 50%, and 75% of the total column\n",
    "2. Replaces each continious value for 4 categorical values, if they are in the range 0-25%, 25-50%, 50-75%, or >75%.\n",
    "3. The Nan values are replace for zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f3680eac-776c-473e-9a00-656b7662a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_continous_cols_in(dataset, testing=False):\n",
    "    # Define the continuous variables that need to be categorized\n",
    "    continuous_columns = [\"m2_MQ\", \"f_MQMR\", \"vs_SSC\", \"vs_SPV\", \"vd_SSF\", \"vd_MSI\"]\n",
    "    def transform_column(name_col, dataset):\n",
    "        q25 = dataset.describe()[name_col]['25%']\n",
    "        q50 = dataset.describe()[name_col]['50%']\n",
    "        q75 = dataset.describe()[name_col]['75%']\n",
    "    \n",
    "        def return_new_(value):\n",
    "            return 1 # just return 1 if it has a value\n",
    "            if value < q25:\n",
    "                return 1\n",
    "            elif value < q50:\n",
    "                return 2\n",
    "            elif value < q75:\n",
    "                return 3\n",
    "            else:\n",
    "                return 4\n",
    "    \n",
    "        # new_dataset[name_col] = dataset[name_col].map(lambda x: return_new_(x), na_action='ignore')\n",
    "        return dataset[name_col].map(return_new_, na_action='ignore')\n",
    "    \n",
    "    # transfrom each columns continious values. \n",
    "    new_dataset = dataset.copy()\n",
    "    for column in continuous_columns:\n",
    "        new_dataset[column] = transform_column(column, new_dataset)\n",
    "        \n",
    "    new_dataset.fillna(0, inplace=True) # transform all nan values\n",
    "\n",
    "    # separate data into x, y values\n",
    "    X = new_dataset.iloc[:, :-1]\n",
    "    y = new_dataset.iloc[:, -1].values\n",
    "    \n",
    "    def OneHotEncoding(dataset2change):\n",
    "        # if testing, then wnat to apply the same oneHotEncoding transformation\n",
    "        if testing:\n",
    "            new_dataset = ct.fit_transform(dataset2change)\n",
    "        else:\n",
    "            new_dataset = ct.fit_transform(dataset2change)\n",
    "            \n",
    "        return new_dataset\n",
    "\n",
    "    X = OneHotEncoding(X)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc2fecb-828f-4d87-aa24-2378100257fe",
   "metadata": {},
   "source": [
    "## Train SVC + SVM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "10633643-1acc-4e2f-b12c-1ba9424716ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188811, 32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = transform_continous_cols_in(only_SNV_callers)\n",
    "print(X.shape)\n",
    "# Linear SVC\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.7, random_state = 0, stratify=y)\n",
    "classifier_linearSVC = LinearSVC(random_state=0, dual=False)  # `dual=False` improves performance for large datasets\n",
    "classifier_linearSVC.fit(X_train, y_train)\n",
    "\n",
    "# Traditinal linear svc\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.90, random_state = 0, stratify=y)\n",
    "classifier_SVC = SVC(kernel='linear', random_state=0) # classic model with the linear kernel\n",
    "classifier_SVC.fit(X_train, y_train)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3083713b-7ab1-448b-a4fa-e9f5a235a8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d06794-26f6-4f5c-98c9-6f403303e7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa70480-60c3-4971-92bd-1ec2f6eef3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe08ca7-e96a-4ae3-affe-324caa460e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e542124-fac3-473d-a90f-6b0c6e8aebcc",
   "metadata": {},
   "source": [
    "# Testing the models for Four Variables\n",
    "We will all the datasets to see how well the model performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2cd9670b-d701-4080-9611-a050d1709d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(dataset, dataset_name, model, model_name):\n",
    "    # Filter to have only the columns that matter\n",
    "    columns_to_read = [\"FILTER_Mutect2\", \"FILTER_Freebayes\", \"FILTER_Vardict\", \"FILTER_Varscan\", \"True_SNV\"]\n",
    "    current_dataset = dataset[columns_to_read]\n",
    "    \n",
    "    # Divide the data in X, y matrices\n",
    "    local_X = current_dataset.iloc[:, :-1].values\n",
    "    local_y = current_dataset.iloc[:, -1].values\n",
    "    \n",
    "    # Get the prediction\n",
    "    y_pred = model.predict(local_X)\n",
    "    \n",
    "    # Check the f1 score\n",
    "    f1 = f1_score(local_y, y_pred)\n",
    "    print(f'The model {model_name} performed in {dataset_name} dataset has an f1 score of: ', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c07cd1-64ce-48d4-bb86-8aa70e739bb6",
   "metadata": {},
   "source": [
    "Datasets that will be used to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "71fa80ea-de7e-457d-93e6-0a917371e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [real1, real2, syn1, syn2, syn3, syn4, syn5]\n",
    "dataset_names = ['rea1', 'real2', 'syn1', 'syn2', 'syn3', 'syn4', 'syn5']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316095c5-1f22-4e0c-a708-c570062a1ed3",
   "metadata": {},
   "source": [
    "## Testing linear SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "524c2e15-36a5-40df-ba82-c34d73e91d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [classifier_linearSVC, classifier_SVC]\n",
    "models_names = ['classifier_linearSVC', 'classifier_SVC']\n",
    "\n",
    "for model, model_name in zip(models, models_names): \n",
    "    for dataset, dataset_name in zip(datasets, dataset_names):\n",
    "        test_model(dataset, dataset_name, model, model_name)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a24545-1fd1-41b8-afdf-5874011451cc",
   "metadata": {},
   "source": [
    "## Testing other SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6c87ef-ebca-4923-9fe5-da4c8a05d629",
   "metadata": {},
   "source": [
    "Testing on the model using random fourier features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b9f839d2-a3d0-4838-885e-73aa5d952359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_rbf(dataset, dataset_name, model, model_name):\n",
    "    # Filter to have only the columns that matter\n",
    "    columns_to_read = [\"FILTER_Mutect2\", \"FILTER_Freebayes\", \"FILTER_Vardict\", \"FILTER_Varscan\", \"True_SNV\"]\n",
    "    current_dataset = dataset[columns_to_read]\n",
    "    \n",
    "    # Divide the data in X, y matrices\n",
    "    local_X = current_dataset.iloc[:, :-1].values\n",
    "    local_y = current_dataset.iloc[:, -1].values\n",
    "\n",
    "    # RBF kernel approximation\n",
    "    rbf_feature = RBFSampler(gamma=1, random_state=0)\n",
    "    X_rbf = rbf_feature.fit_transform(local_X)\n",
    "    \n",
    "    # Get the prediction\n",
    "    y_pred = model.predict(X_rbf)\n",
    "    \n",
    "    # Check the f1 score\n",
    "    f1 = f1_score(local_y, y_pred)\n",
    "    print(f'The model {model_name} performed in {dataset_name} dataset has an f1 score of: ', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5fb18c0e-138c-4cca-8bb9-2d697f8e1f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model SGDClassifier performed in rea1 dataset has an f1 score of:  0.8089401586157173\n",
      "The model SGDClassifier performed in real2 dataset has an f1 score of:  0.6488352027610008\n",
      "The model SGDClassifier performed in syn1 dataset has an f1 score of:  0.9077771939043615\n",
      "The model SGDClassifier performed in syn2 dataset has an f1 score of:  0.9042382833351126\n",
      "The model SGDClassifier performed in syn3 dataset has an f1 score of:  0.9608814708566958\n",
      "The model SGDClassifier performed in syn4 dataset has an f1 score of:  0.8931939469259449\n",
      "The model SGDClassifier performed in syn5 dataset has an f1 score of:  0.9804949783974191\n",
      "\n",
      "The model rbf_feature performed in rea1 dataset has an f1 score of:  0.8089401586157173\n",
      "The model rbf_feature performed in real2 dataset has an f1 score of:  0.6488352027610008\n",
      "The model rbf_feature performed in syn1 dataset has an f1 score of:  0.9077771939043615\n",
      "The model rbf_feature performed in syn2 dataset has an f1 score of:  0.9042382833351126\n",
      "The model rbf_feature performed in syn3 dataset has an f1 score of:  0.9608814708566958\n",
      "The model rbf_feature performed in syn4 dataset has an f1 score of:  0.8931939469259449\n",
      "The model rbf_feature performed in syn5 dataset has an f1 score of:  0.9804949783974191\n",
      "\n",
      "The model classifier_rbf_approx  performed in rea1 dataset has an f1 score of:  0.8089401586157173\n",
      "The model classifier_rbf_approx  performed in real2 dataset has an f1 score of:  0.6488352027610008\n",
      "The model classifier_rbf_approx  performed in syn1 dataset has an f1 score of:  0.9077771939043615\n",
      "The model classifier_rbf_approx  performed in syn2 dataset has an f1 score of:  0.9042382833351126\n",
      "The model classifier_rbf_approx  performed in syn3 dataset has an f1 score of:  0.9608814708566958\n",
      "The model classifier_rbf_approx  performed in syn4 dataset has an f1 score of:  0.8931939469259449\n",
      "The model classifier_rbf_approx  performed in syn5 dataset has an f1 score of:  0.9804949783974191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [sgd_rbf, log_reg, classifier_rbf_approx ]\n",
    "models_names = ['SGDClassifier', 'rbf_feature', 'classifier_rbf_approx ']\n",
    "\n",
    "for model, model_name in zip(models, models_names): \n",
    "    for dataset, dataset_name in zip(datasets, dataset_names):\n",
    "        test_model_rbf(dataset, dataset_name, model, model_name)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011999e7-a3e4-4cb2-a05b-667494839178",
   "metadata": {},
   "source": [
    "# Testing the model with variant callers quality controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ad020d20-a043-4abc-9fd3-fabde79c82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(dataset, dataset_name, model, model_name):\n",
    "    # Filter to have only the columns that matter\n",
    "    columns_to_read = [\"FILTER_Mutect2\", \"FILTER_Freebayes\", \"FILTER_Vardict\", \"FILTER_Varscan\", \"m2_MQ\", \"f_MQMR\", \"vs_SSC\", \"vs_SPV\", \"vd_SSF\", \"vd_MSI\", \"True_SNV\"]\n",
    "    current_dataset = dataset[columns_to_read]\n",
    "    \n",
    "    # Divide the data in X, y matrices\n",
    "    local_X, local_y = transform_continous_cols_in(current_dataset, True)\n",
    "    print(local_X.shape)\n",
    "    # Get the prediction\n",
    "    y_pred = model.predict(local_X)\n",
    "    \n",
    "    # Check the f1 score\n",
    "    f1 = f1_score(local_y, y_pred)\n",
    "    print(f'The model {model_name} performed in {dataset_name} dataset has an f1 score of: ', f1)\n",
    "\n",
    "datasets = [real1, real2, syn1, syn2, syn3, syn4, syn5]\n",
    "dataset_names = ['rea1', 'real2', 'syn1', 'syn2', 'syn3', 'syn4', 'syn5']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5ad057-e44e-4c77-bdd9-24c3265114c1",
   "metadata": {},
   "source": [
    "## Testing Linear SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89bafef-3982-4772-8c2b-e03804a6f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [classifier_linearSVC, classifier_SVC]\n",
    "models_names = ['classifier_linearSVC', 'classifier_SVC']\n",
    "\n",
    "for model, model_name in zip(models, models_names): \n",
    "    for dataset, dataset_name in zip(datasets, dataset_names):\n",
    "        test_model(dataset, dataset_name, model, model_name)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
